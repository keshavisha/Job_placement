{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keshavisha/Job_placement/blob/main/Model_Parthib_Isha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "5DcltSdSpScP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.tracebacklimit = None"
      ],
      "metadata": {
        "id": "O2kIr4rWGFtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from catboost import  CatBoostRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('Placement_Data_Full_Class.xls')\n",
        "dataset=dataset.drop(['sl_no'],axis=1)\n",
        "# One-hot encode the categorical features\n",
        "categorical_cols = ['gender', 'ssc_b', 'hsc_b', 'hsc_s', 'degree_t', 'workex', 'specialisation']\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "encoded_cols = pd.DataFrame(encoder.fit_transform(dataset[categorical_cols]))\n",
        "encoded_cols.columns = encoder.get_feature_names_out(categorical_cols)\n",
        "dataset.drop(categorical_cols ,axis=1, inplace=True)\n",
        "dataset = pd.concat([dataset, encoded_cols], axis=1)\n",
        "\n",
        "# Split the dataset into features and target variables\n",
        "X = dataset.drop(['status', 'salary'], axis=1)\n",
        "y = dataset['status']\n",
        "\n",
        "# Fit the PCA model to the feature matrix\n",
        "pca = PCA(n_components=7)\n",
        "pca.fit(X)\n",
        "\n",
        "# Apply the PCA transformation to the feature matrix\n",
        "X = pca.transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)\n",
        "\n",
        "# Train the classification model\n",
        "clf_model = LogisticRegression()\n",
        "clf_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the performance of the classification model\n",
        "clf_accuracy = clf_model.score(X_test, y_test)\n",
        "\n",
        "\n",
        "# Filter the data for candidates who were placed\n",
        "placed_data = dataset[dataset['status'] == 'Placed']\n",
        "\n",
        "# Split the placed data into features and target variables\n",
        "placed_data1=placed_data[placed_data['salary']<400000]\n",
        "X_placed = placed_data1.drop(['status', 'salary'], axis=1)\n",
        "y_placed = placed_data['salary']\n",
        "y_placed=y_placed[y_placed<400000]\n",
        "# Normalize the target variable\n",
        "scaler = MinMaxScaler()\n",
        "y_placed = scaler.fit_transform(y_placed.values.reshape(-1, 1))\n",
        "\n",
        "# Apply the PCA transformation to the placed data\n",
        "X_placed = pca.transform(X_placed)\n",
        "\n",
        "# Split the placed data into training and testing sets\n",
        "X_placed_train, X_placed_test, y_placed_train, y_placed_test = train_test_split(X_placed, y_placed, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the regression model on the placed data\n",
        "reg_model = CatBoostRegressor(learning_rate=0.4,reg_lambda=0.24, loss_function='RMSE', iterations=7500)\n",
        "reg_model.fit(X_placed_train, y_placed_train)\n",
        "\n",
        "\n",
        "# Save the models and PCA object\n",
        "# Evaluate the performance of the regression model\n",
        "y_placed_pred = reg_model.predict(X_placed_test)\n",
        "print(\"MSE R2:\", mean_squared_error(y_placed_test,y_placed_pred))\n",
        "print(\"Classification accuracy: {:.2f}%\".format(clf_accuracy * 100))\n",
        "# Save the models and PCA object\n",
        "joblib.dump(encoder, 'placement_encoder.joblib')\n",
        "joblib.dump(clf_model, 'placement_classifier.joblib')\n",
        "joblib.dump(reg_model, 'placement_regressor.joblib')\n",
        "joblib.dump(pca, 'placement_pca.joblib')\n",
        "joblib.dump(scaler, 'placement_scaler.joblib')\n",
        "#OUTPUT: Streaming output truncated to the last 5000 lines.\n",
        "#2502:\tlearn: 0.0000000\ttotal: 2.29s\tremaining: 4.58s\n",
        "#2503:\tlearn: 0.0000000\ttotal: 2.29s\tremaining: 4.58s\n",
        "#2504:\tlearn: 0.0000000\ttotal: 2.3s\tremaining: 4.58s\n",
        "#2505:\tlearn: 0.0000000\ttotal: 2.3s\tremaining: 4.58s\n",
        "#2506:\tlearn: 0.0000000\ttotal: 2.3s\tremaining: 4.58s"
      ],
      "metadata": {
        "id": "No58wORapRQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_salary(record):\n",
        "    # Load the PCA object from file\n",
        "    pca = joblib.load('/content/placement_pca.joblib')\n",
        "    \n",
        "    # Load the encoder object from file\n",
        "    encoder = joblib.load('/content/placement_encoder.joblib')\n",
        "    \n",
        "    # Load the classification model from file\n",
        "    clf_model = joblib.load('/content/placement_classifier.joblib')\n",
        "    \n",
        "    # Load the regression model from file\n",
        "    reg_model = joblib.load('/content/placement_regressor.joblib')\n",
        "    \n",
        "    # Load the scaler object from file\n",
        "    scaler = joblib.load('/content/placement_scaler.joblib')\n",
        "    \n",
        "    # Convert the record to a dataframe with a single row\n",
        "    df = pd.DataFrame([record])\n",
        "    \n",
        "    # One-hot encode the categorical features\n",
        "    categorical_cols = ['gender', 'ssc_b', 'hsc_b', 'hsc_s', 'degree_t', 'workex', 'specialisation']\n",
        "    encoded_cols = pd.DataFrame(encoder.transform(df[categorical_cols]))\n",
        "    encoded_cols.columns = encoder.get_feature_names_out(categorical_cols)\n",
        "    df.drop(categorical_cols ,axis=1, inplace=True)\n",
        "    df = pd.concat([df, encoded_cols], axis=1)\n",
        "    \n",
        "    # Apply the PCA transformation to the input record\n",
        "    transformed_record = pca.transform(df)\n",
        "\n",
        "    # Predict the placement status\n",
        "    classification_prediction = clf_model.predict(transformed_record)[0]\n",
        "    print(classification_prediction)\n",
        "    \n",
        "    if classification_prediction == 'Placed':\n",
        "        # Predict the salary\n",
        "        regression_prediction = reg_model.predict(transformed_record)[0]\n",
        "        # Inverse transform the scaled salary value to get the actual salary\n",
        "        predicted_salary = scaler.inverse_transform(np.array(regression_prediction).reshape(-1,1))[0][0]\n",
        "        return predicted_salary\n",
        "    else:\n",
        "        return \"Not placed\"\n"
      ],
      "metadata": {
        "id": "vtd54EGaxCFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "record = {\n",
        "    'gender': 'M',\n",
        "    'ssc_p': 83.0,\n",
        "    'ssc_b': 'Central',\n",
        "    'hsc_p': 88.0,\n",
        "    'hsc_b': 'Central',\n",
        "    'hsc_s': 'Science',\n",
        "    'degree_p': 87.0,\n",
        "    'degree_t': 'Sci&Tech',\n",
        "    'workex': 'No',\n",
        "    'etest_p': 83.0,\n",
        "    'specialisation': 'Mkt&Fin',\n",
        "    'mba_p': 88.8\n",
        "}\n",
        "\n",
        "predict_salary(record)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_0cGho-ahMP",
        "outputId": "6cba2b3b-48ad-4c8f-faf9-c574c535015a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Placed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "275425.16043760837"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    }
  ]
}
